{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "id": "q6Lj4GQOJ5wK"
      },
      "source": [
        "# PyTorch basics - Linear Regression from scratch\n",
        "\n",
        "<!-- <iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/ECHX1s0Kk-o?controls=0\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe> -->\n",
        "\n",
        "\n",
        "## Tensors & Gradients"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q3VUep9gBFiK",
        "outputId": "1f178025-1266-4008-ab39-47fd4bd78b97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torch\n",
            "  Downloading torch-1.13.1-cp310-cp310-win_amd64.whl (162.6 MB)\n",
            "     ------------------------------------ 162.6/162.6 MB 912.8 kB/s eta 0:00:00\n",
            "Collecting typing-extensions\n",
            "  Downloading typing_extensions-4.4.0-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: typing-extensions, torch\n",
            "Successfully installed torch-1.13.1 typing-extensions-4.4.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip available: 22.3.1 -> 23.0\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "id": "unxZnHwEJ5wN"
      },
      "outputs": [],
      "source": [
        "# Import Numpy & PyTorch\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "34f006aa7eb4bbc683c39b7059021da900180908",
        "id": "TUClekcMJ5wO"
      },
      "source": [
        "A tensor is a number, vector, matrix or any n-dimensional array:\n",
        "\n",
        "<image src=\"https://miro.medium.com/max/1400/1*GbwKkmA0NdndXRhOOwNclA.jpeg\">\n",
        "\n",
        "\n",
        "In PyTorch, Tensors are objects that wrap an N-dimensional array of numbers. We use them to perform computations on GPU, and to **automatically differentiate** our functions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "e22be3f71825128f990e78959fa00d1331d344e4",
        "id": "IXnrwLfZJ5wO"
      },
      "outputs": [],
      "source": [
        "# Create tensors.\n",
        "x = torch.tensor(3.)\n",
        "w = torch.tensor(4., requires_grad=True)\n",
        "b = torch.tensor(5., requires_grad=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "3cb90767ff9bc2c12b72548b1a430984241d4910",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2oY2vBDBJ5wP",
        "outputId": "f75f356c-e928-434d-acce-4ca464deff0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(3.)\n",
            "tensor(4., requires_grad=True)\n",
            "tensor(5., requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "# Print tensors\n",
        "print(x)\n",
        "print(w)\n",
        "print(b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "66a939ee0ec472705acd3f23654bc3ccea1cc8b4",
        "id": "Pn0NEQlXJ5wP"
      },
      "source": [
        "We can combine tensors with the usual arithmetic operations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "0bd8fdeb252742e3449b7a2f08bcb188645dc9cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYmUrFetJ5wP",
        "outputId": "4d1d0fd2-3104-432a-cf21-c85e956119fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(17., grad_fn=<AddBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# Arithmetic operations\n",
        "y = w * x + b\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "64e0f175c65c3e875c671c40e4a9bf495e30b772",
        "id": "a1EXQul0J5wQ"
      },
      "source": [
        "What makes PyTorch special, is that we can automatically compute the derivative of `y` w.r.t. the tensors that have `requires_grad` set to `True` i.e. `w` and `b`.  (remember how much we worked for our partial derivatives?)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "6c98996f00294f99eb11989b5a9ecdbda31864e1",
        "id": "_JbwGwiCJ5wQ"
      },
      "outputs": [],
      "source": [
        "# Compute gradients\n",
        "y.backward()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "47a62ffb26a76329e511f9f063c4c26cc6a7dc21",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iOYVjiubJ5wR",
        "outputId": "b22c5b24-5eb8-42f1-c554-c8cf540d65c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dy/dw: tensor(3.)\n",
            "dy/db: tensor(1.)\n"
          ]
        }
      ],
      "source": [
        "# Display gradients\n",
        "print('dy/dw:', w.grad)\n",
        "print('dy/db:', b.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "0b65b6bb4d15127b1d51f09abf616cfd29fa48b4",
        "id": "o2_PeuljJ5wR"
      },
      "source": [
        "# Excercise - Linear regression\n",
        "##Problem Statement"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "c1beecda01bc332596edd193cade30006e3f6cbf",
        "id": "prtLSg5XJ5wR"
      },
      "source": [
        "We'll create a model that predicts crop yeilds for apples and oranges (*target variables*) by looking at the average temperature, rainfall and humidity (*input variables or features*) in a region. Here's the training data:\n",
        "\n",
        "<img src=\"https://i.imgur.com/lBguUV9.png\" width=\"500\" />\n",
        "\n",
        "In a **linear regression** model, each target variable is estimated to be a weighted sum of the input variables, offset by some constant, known as a bias :\n",
        "\n",
        "```\n",
        "yeild_apple  = w11 * temp + w12 * rainfall + w13 * humidity + b1\n",
        "yeild_orange = w21 * temp + w22 * rainfall + w23 * humidity + b2\n",
        "```\n",
        "\n",
        "Visually, it means that the yield of apples is a linear or planar function of the temperature, rainfall & humidity.\n",
        "\n",
        "<img src=\"https://i.imgur.com/mtkR2lB.png\" width=\"540\" >\n",
        "\n",
        "\n",
        "**Our objective**: Find a suitable set of *weights* and *biases* using the training data, to make accurate predictions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "c24b8195c0e9c6e8e13e169d264484f1f9b3b1ae",
        "id": "gQQDxZM2J5wS"
      },
      "source": [
        "## Training Data\n",
        "The training data can be represented using 2 matrices (inputs and targets), each with one row per observation and one column per variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "dfda99005fc6daf3a49ae1cdd427ccac0aa446b1",
        "id": "bB4m9ZiPJ5wS"
      },
      "outputs": [],
      "source": [
        "# Input (temp, rainfall, humidity)\n",
        "inputs = np.array([[73, 67, 43], \n",
        "                   [91, 88, 64], \n",
        "                   [87, 134, 58], \n",
        "                   [102, 43, 37], \n",
        "                   [69, 96, 70]], dtype='float32')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "bf56faf74f7e29c9ed7523308718a9ab1acc0667",
        "id": "ea7C17TJJ5wS"
      },
      "outputs": [],
      "source": [
        "# Targets (apples, oranges)\n",
        "targets = np.array([[56, 70], \n",
        "                    [81, 101], \n",
        "                    [119, 133], \n",
        "                    [22, 37], \n",
        "                    [103, 119]], dtype='float32')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "70d48f83ae4fce7aba7dd78fd58dddc77c598bfd",
        "id": "yWzG0FZbJ5wS"
      },
      "source": [
        "Before we build a model, we need to convert inputs and targets to PyTorch tensors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "652647cd90bd0784ec4dc53472410f7358ee18c9",
        "id": "nArXz8umJ5wT"
      },
      "source": [
        "## Linear Regression Model (from scratch)\n",
        "\n",
        "Let's define the three functions we used before:\n",
        "1. Output prediction (our architecture):\n",
        "\n",
        "$$y_{apples} = w_{11}*temp + w_{12}*rainfall + w_{12}*humidity + b_1$$\n",
        "$$y_{oranges} = w_{21}*temp + w_{22}*rainfall + w_{32}*humidity + b_2$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "b1119f5ae9688a5f31dba438c7f78ca382deb7e3",
        "id": "UaD_XprOJ5wT"
      },
      "outputs": [],
      "source": [
        "# Define the model architecture\n",
        "def output_formula(features, weights, biases):\n",
        "    return features @ weights.t() + biases"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "3579a065997cae41f7f504916b6bc07878ac768c",
        "id": "VKIe3xguJ5wT"
      },
      "source": [
        "Another option is to look at our *model* as simply a function that performs a matrix multiplication of the input `x` and the weights `w` (transposed) and adds the bias `b` (replicated for each observation).\n",
        "\n",
        "$$\n",
        "\\hspace{2.5cm} X \\hspace{1.1cm} \\times \\hspace{1.2cm} W^T \\hspace{1.2cm}  + \\hspace{1cm} b \\hspace{2cm}\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\left[ \\begin{array}{cc}\n",
        "73 & 67 & 43 \\\\\n",
        "91 & 88 & 64 \\\\\n",
        "\\vdots & \\vdots & \\vdots \\\\\n",
        "69 & 96 & 70\n",
        "\\end{array} \\right]\n",
        "%\n",
        "\\times\n",
        "%\n",
        "\\left[ \\begin{array}{cc}\n",
        "w_{11} & w_{21} \\\\\n",
        "w_{12} & w_{22} \\\\\n",
        "w_{13} & w_{23}\n",
        "\\end{array} \\right]\n",
        "%\n",
        "+\n",
        "%\n",
        "\\left[ \\begin{array}{cc}\n",
        "b_{1} & b_{2} \\\\\n",
        "b_{1} & b_{2} \\\\\n",
        "\\vdots & \\vdots \\\\\n",
        "b_{1} & b_{2} \\\\\n",
        "\\end{array} \\right]\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ptkz-7SSRcIB"
      },
      "outputs": [],
      "source": [
        "# Matrix notation\n",
        "def output_formula_matrix(features, weights, biases):\n",
        "    return features @ weights.t() + biases"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "8e0a4644cb1c4ed68a3bcf67a8a156341ac7c853",
        "id": "iFwt6FueJ5wT"
      },
      "source": [
        "The matrix obtained by passing the input data to the model is a set of predictions for the target variables."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GdwvLWZgRrPU"
      },
      "source": [
        "2. Loss function (same as before)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "dbf5bca8cbf2a3831089b454c70469e3748e9682",
        "id": "HY6xDBnrJ5wU"
      },
      "outputs": [],
      "source": [
        "# MSE loss\n",
        "def error_formula(y, output):\n",
        "    diff = y - output\n",
        "    return torch.sum(diff * diff) / diff.numel()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmR_m2rKSFa9"
      },
      "source": [
        "3. Weight update step:\n",
        "\n",
        "\n",
        "$$ w_{ij} \\longrightarrow w_{ij} + \\alpha \\frac{\\partial L}{\\partial w_{ij}}$$\n",
        "\n",
        "$$ b_i \\longrightarrow b_i + \\alpha \\frac{\\partial L}{\\partial b_i}$$\n",
        "\n",
        "Wait! This is a much more complicated function then we had before. How are we supposed to get the gradient for all these weights?\n",
        "\n",
        "Luckily, this is just what PyTorch is for - once we compute the loss on some inputs, we can just call __loss.backward()__ and the gradients will be calculated for all of the weights automatically.\n",
        "\n",
        "Let's see a live example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "931c1bad8788e607fa100d4338e1b1fe120e2339",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AU536g_gJ5wS",
        "outputId": "9a43cc34-8c93-439f-d440-5e06aeeb0c75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 73.,  67.,  43.],\n",
            "        [ 91.,  88.,  64.],\n",
            "        [ 87., 134.,  58.],\n",
            "        [102.,  43.,  37.],\n",
            "        [ 69.,  96.,  70.]])\n",
            "tensor([[ 56.,  70.],\n",
            "        [ 81., 101.],\n",
            "        [119., 133.],\n",
            "        [ 22.,  37.],\n",
            "        [103., 119.]])\n"
          ]
        }
      ],
      "source": [
        "# Convert inputs and targets to tensors\n",
        "inputs = torch.from_numpy(inputs)\n",
        "targets = torch.from_numpy(targets)\n",
        "print(inputs)\n",
        "print(targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "6f788ae559355b3f01667be1554a5d2bdcade8db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9-ArRiCGJ5wT",
        "outputId": "7d8cf84c-1293-4885-a8a6-257ca2055e80"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 0.6936,  0.1105,  1.2003],\n",
            "        [-0.5451, -0.1781, -1.8158]], requires_grad=True)\n",
            "tensor([-0.1499, -0.1415], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "# Weights and biases\n",
        "w = torch.randn(2, 3, requires_grad=True)\n",
        "b = torch.randn(2, requires_grad=True)\n",
        "print(w)\n",
        "print(b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "ef0d2bd2d9c5acb60992e238439ee00c2223319f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fcm71_CgJ5wX",
        "outputId": "d6a74d3d-f052-4e51-8808-10ef35d96bca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 109.4973, -129.9449],\n",
            "        [ 149.5080, -181.6285],\n",
            "        [ 144.6160, -176.7451],\n",
            "        [ 119.7572, -130.5833],\n",
            "        [ 142.3348, -181.9564]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# Generate predictions\n",
        "preds = output_formula_matrix(inputs, w, b)\n",
        "print(preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j14-OySHBFiR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "90da6779aad81608c40cdca77c3c04b68a815c11",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2mmqlh3J5wV",
        "outputId": "117037b7-7b3e-4d46-b2d5-69df908abaec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(35377.2930, grad_fn=<DivBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# Compute loss\n",
        "loss = error_formula(targets, preds)\n",
        "print(loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "ef66710c6ef1944567c4dc033e1ca316f35490ab",
        "id": "yXj2u22MJ5wV"
      },
      "outputs": [],
      "source": [
        "# Compute gradients\n",
        "loss.backward()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "6504cddcfb4bfb0817bf03ef460f08f3145a9091",
        "id": "-ym_IzQKJ5wV"
      },
      "source": [
        "As we've see, the gradients are stored in the `.grad` property of the respective tensors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hCJXCTfyWHPT",
        "outputId": "a96fc8fd-8b1a-48a5-a77b-3befadf2967d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[  5010.6914,   4205.0532,   2908.2151],\n",
            "        [-21024.4980, -23174.2734, -14383.7207]])\n",
            "tensor([  56.9427, -252.1716])\n"
          ]
        }
      ],
      "source": [
        "print(w.grad)\n",
        "print(b.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "demaQs0sWM5O"
      },
      "source": [
        "Let's proceed to write our update function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "b042a3cf8f16f4c4380cccbac9d0892719c24190",
        "id": "h-8RomEkJ5wU"
      },
      "outputs": [],
      "source": [
        "# Gradient descent step\n",
        "def update_weights(x, y, weights, biases, learn_rate):\n",
        "    preds = output_formula_matrix(x, weights, biases)\n",
        "    loss = error_formula(y, preds)\n",
        "    loss.backward()\n",
        "\n",
        "    with torch.no_grad():\n",
        "      new_weights = weights - learn_rate * weights.grad\n",
        "      new_biases = biases - learn_rate * biases.grad\n",
        "\n",
        "      weights.copy_(new_weights)\n",
        "      biases.copy_(new_biases)\n",
        "\n",
        "      weights.grad.zero_()\n",
        "      biases.grad.zero_()\n",
        "\n",
        "    return weights, biases"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "5501c66c9729c4954e9b798a0634a9d84487e639",
        "id": "NhG5KRJxJ5wX"
      },
      "source": [
        "## Adjust weights and biases using gradient descent\n",
        "\n",
        "We'll reduce the loss and improve our model using the gradient descent algorithm, which has the following steps:\n",
        "\n",
        "1. Generate predictions\n",
        "2. Calculate the loss\n",
        "3. Compute gradients w.r.t the weights and biases\n",
        "4. Adjust the weights by subtracting a small quantity proportional to the gradient\n",
        "5. Reset the gradients to zero"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "5201901695f3ea13d7fdd5d985da7e0761c541d0",
        "id": "k-11TOopJ5wY"
      },
      "source": [
        "## Train for multiple epochs\n",
        "\n",
        "Let's rereun our training function from before:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "9f5f0ffeee666b30c5828636359f0be6addbef7c",
        "id": "4dVGBzTLJ5wY"
      },
      "outputs": [],
      "source": [
        "def train(features, targets, epochs, learnrate):\n",
        "    \n",
        "    errors = []\n",
        "    last_loss = None\n",
        "\n",
        "    # Init model weights\n",
        "    w = torch.randn(2, 3, requires_grad=True)\n",
        "    b = torch.randn(2, requires_grad=True)\n",
        "\n",
        "    for e in range(epochs):\n",
        "        for x, y in zip(features, targets):\n",
        "            w, b = update_weights(x, y, w, b, learnrate)\n",
        "\n",
        "        out = output_formula(features, w, b)\n",
        "        loss = error_formula(targets, out)\n",
        "        errors.append(loss)\n",
        "\n",
        "    return errors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "addec2c4eca8edfcae5544ea2cc717182c21d90f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 745
        },
        "id": "GkC-Vob7J5wY",
        "outputId": "7e5a0e02-334c-466f-abe5-4911abad8f30"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[21], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNumber of epochs\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      9\u001b[0m plt\u001b[38;5;241m.\u001b[39mylabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\matplotlib\\pyplot.py:2740\u001b[0m, in \u001b[0;36mplot\u001b[1;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2738\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mplot)\n\u001b[0;32m   2739\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot\u001b[39m(\u001b[38;5;241m*\u001b[39margs, scalex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, scaley\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m-> 2740\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m gca()\u001b[38;5;241m.\u001b[39mplot(\n\u001b[0;32m   2741\u001b[0m         \u001b[38;5;241m*\u001b[39margs, scalex\u001b[38;5;241m=\u001b[39mscalex, scaley\u001b[38;5;241m=\u001b[39mscaley,\n\u001b[0;32m   2742\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m: data} \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\matplotlib\\axes\\_axes.py:1662\u001b[0m, in \u001b[0;36mAxes.plot\u001b[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1419\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1420\u001b[0m \u001b[38;5;124;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[0;32m   1421\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1659\u001b[0m \u001b[38;5;124;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[0;32m   1660\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1661\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m cbook\u001b[38;5;241m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[38;5;241m.\u001b[39mLine2D)\n\u001b[1;32m-> 1662\u001b[0m lines \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_lines(\u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39mdata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)]\n\u001b[0;32m   1663\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[0;32m   1664\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_line(line)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\matplotlib\\axes\\_base.py:311\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[1;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m     this \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    310\u001b[0m     args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plot_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    312\u001b[0m \u001b[43m    \u001b[49m\u001b[43mthis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\matplotlib\\axes\\_base.py:496\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[1;34m(self, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[0;32m    494\u001b[0m     y \u001b[38;5;241m=\u001b[39m _check_1d(xy[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m    495\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 496\u001b[0m     x, y \u001b[38;5;241m=\u001b[39m \u001b[43mindex_of\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxy\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes\u001b[38;5;241m.\u001b[39mxaxis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    499\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes\u001b[38;5;241m.\u001b[39mxaxis\u001b[38;5;241m.\u001b[39mupdate_units(x)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\matplotlib\\cbook\\__init__.py:1690\u001b[0m, in \u001b[0;36mindex_of\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m   1688\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1689\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1690\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43m_check_1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1691\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (np\u001b[38;5;241m.\u001b[39mVisibleDeprecationWarning, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[0;32m   1692\u001b[0m     \u001b[38;5;66;03m# NumPy 1.19 will warn on ragged input, and we can't actually use it.\u001b[39;00m\n\u001b[0;32m   1693\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\matplotlib\\cbook\\__init__.py:1382\u001b[0m, in \u001b[0;36m_check_1d\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1376\u001b[0m \u001b[38;5;66;03m# plot requires `shape` and `ndim`.  If passed an\u001b[39;00m\n\u001b[0;32m   1377\u001b[0m \u001b[38;5;66;03m# object that doesn't provide them, then force to numpy array.\u001b[39;00m\n\u001b[0;32m   1378\u001b[0m \u001b[38;5;66;03m# Note this will strip unit information.\u001b[39;00m\n\u001b[0;32m   1379\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1380\u001b[0m         \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1381\u001b[0m         \u001b[38;5;28mlen\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m-> 1382\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43matleast_1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1383\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1384\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
            "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36matleast_1d\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\core\\shape_base.py:65\u001b[0m, in \u001b[0;36matleast_1d\u001b[1;34m(*arys)\u001b[0m\n\u001b[0;32m     63\u001b[0m res \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ary \u001b[38;5;129;01min\u001b[39;00m arys:\n\u001b[1;32m---> 65\u001b[0m     ary \u001b[38;5;241m=\u001b[39m \u001b[43masanyarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mary\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ary\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     67\u001b[0m         result \u001b[38;5;241m=\u001b[39m ary\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_tensor.py:956\u001b[0m, in \u001b[0;36mTensor.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m    954\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[38;5;241m.\u001b[39m__array__, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    955\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 956\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    957\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    958\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
            "\u001b[1;31mRuntimeError\u001b[0m: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead."
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "epochs = 50\n",
        "learnrate = 1e-5\n",
        "\n",
        "errors = train(inputs, targets, epochs, learnrate)\n",
        "\n",
        "# Plotting the error\n",
        "plt.title(\"Error Plot\")\n",
        "plt.xlabel('Number of epochs')\n",
        "plt.ylabel('Error')\n",
        "plt.plot(errors)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ieCbm8weBFiT"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}